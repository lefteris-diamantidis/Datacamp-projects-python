{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35aebf2e-0635-4fef-bc9a-877b6a20fb13",
   "metadata": {},
   "source": [
    "![Credit card being held in hand](credit_card.jpg)\n",
    "\n",
    "Commercial banks receive _a lot_ of applications for credit cards. Many of them get rejected for many reasons, like high loan balances, low income levels, or too many inquiries on an individual's credit report, for example. Manually analyzing these applications is mundane, error-prone, and time-consuming (and time is money!). Luckily, this task can be automated with the power of machine learning and pretty much every commercial bank does so nowadays. In this workbook, you will build an automatic credit card approval predictor using machine learning techniques, just like real banks do.\n",
    "\n",
    "### The Data\n",
    "\n",
    "The data is a small subset of the Credit Card Approval dataset from the UCI Machine Learning Repository showing the credit card applications a bank receives. This dataset has been loaded as a `pandas` DataFrame called `cc_apps`. The last column in the dataset is the target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5eecb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0      1      2  3  4  5  6     7  8  9   10 11   12 13\n",
      "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  g    0  +\n",
      "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  g  560  +\n",
      "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  g  824  +\n",
      "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  g    3  +\n",
      "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  s    0  +\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the dataset\n",
    "cc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \n",
    "print(cc_apps.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e27b3f",
   "metadata": {},
   "source": [
    "Use supervised learning techniques to automate the credit card approval process for banks.\n",
    "\n",
    "- Preproccess the data and apply supervised learning techniques to find the best model and parameters for the job. Save the accuracy score from your best model as a numeric variable, best_score. Aim for an accuracy score of at least 0.75. The target variable is the last column of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed0cea19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       690 non-null    object \n",
      " 1   1       690 non-null    object \n",
      " 2   2       690 non-null    float64\n",
      " 3   3       690 non-null    object \n",
      " 4   4       690 non-null    object \n",
      " 5   5       690 non-null    object \n",
      " 6   6       690 non-null    object \n",
      " 7   7       690 non-null    float64\n",
      " 8   8       690 non-null    object \n",
      " 9   9       690 non-null    object \n",
      " 10  10      690 non-null    int64  \n",
      " 11  11      690 non-null    object \n",
      " 12  12      690 non-null    int64  \n",
      " 13  13      690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(10)\n",
      "memory usage: 75.6+ KB\n"
     ]
    }
   ],
   "source": [
    "cc_apps.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "880ee9aa-2da0-40d8-9b92-d152fc5916c7",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 59,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "cc_apps_nans_replaced = cc_apps.replace(\"?\", np.NaN)\n",
    "cc_apps_imputed = cc_apps_nans_replaced.copy()\n",
    "\n",
    "for col in cc_apps_imputed.columns:\n",
    "    if cc_apps_imputed[col].dtypes == \"object\":\n",
    "        cc_apps_imputed[col] = cc_apps_imputed[col].fillna(cc_apps_imputed[col].value_counts().index[0])\n",
    "    else:\n",
    "        cc_apps_imputed[col] = cc_apps_imputed[col].fillna(cc_apps_imputed[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16c89c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummify the categorical features\n",
    "cc_apps_encoded = pd.get_dummies(cc_apps_imputed, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3370a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cc_apps_encoded.iloc[:, :-1].values\n",
    "y = cc_apps_encoded.iloc[:, [-1]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88f0ec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "243a4e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[203   1]\n",
      " [  1 257]]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit logreg to the train set\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use logreg to predict instances from the training set\n",
    "y_train_pred = logreg.predict(X_train_scaled)\n",
    "\n",
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3aaf012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.793859649122807\n"
     ]
    }
   ],
   "source": [
    "print(logreg.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4fc7cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = [0.01, 0.001, 0.0001]\n",
    "max_iter = [100, 150, 200]\n",
    "\n",
    "\n",
    "param_grid = dict(tol=tol, max_iter=max_iter)\n",
    "\n",
    "grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n",
    "\n",
    "grid_model_result = grid_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30bae21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.818256 using {'max_iter': 100, 'tol': 0.01}\n",
      "Accuracy of logistic regression classifier:  0.7982456140350878\n"
     ]
    }
   ],
   "source": [
    "best_train_score, best_train_params = grid_model_result.best_score_, grid_model_result.best_params_\n",
    "print(\"Best: %f using %s\" % (best_train_score, best_train_params))\n",
    "\n",
    "# Extract the best model and evaluate it on the test set\n",
    "best_model = grid_model_result.best_estimator_\n",
    "best_score =  best_model.score(X_test_scaled, y_test)\n",
    "\n",
    "print(\"Accuracy of logistic regression classifier: \", best_score)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
