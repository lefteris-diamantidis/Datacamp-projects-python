{"cells":[{"source":"![Shopping trolley in front of a laptop](./iStock-1249219777.jpg)\n\nIt's simple to buy any product with a click and have it delivered to your door. Online shopping has been rapidly evolving over the last few years, making our lives easier. But behind the scenes, e-commerce companies face a complex challenge that needs to be addressed. \n\nUncertainty plays a big role in how the supply chains plan and organize their operations to ensure that the products are delivered on time. These uncertainties can lead to challenges such as stockouts, delayed deliveries, and increased operational costs.\n\nYou work for the Sales & Operations Planning (S&OP) team at a multinational e-commerce company. They need your help to assist in planning for the upcoming end-of-the-year sales. They want to use your insights to plan for promotional opportunities and manage their inventory. This effort is to ensure they have the right products in stock when needed and ensure their customers are satisfied with the prompt delivery to their doorstep.\n\n\n## The Data\n\nYou are provided with a sales dataset to use. A summary and preview are provided below.\n\n# Online Retail.csv\n\n| Column     | Description              |\n|------------|--------------------------|\n| `'InvoiceNo'` | A 6-digit number uniquely assigned to each transaction |\n| `'StockCode'` | A 5-digit number uniquely assigned to each distinct product |\n| `'Description'` | The product name |\n| `'Quantity'` | The quantity of each product (item) per transaction |\n| `'UnitPrice'` | Product price per unit |\n| `'CustomerID'` | A 5-digit number uniquely assigned to each customer |\n| `'Country'` | The name of the country where each customer resides |\n| `'InvoiceDate'` | The day and time when each transaction was generated `\"MM/DD/YYYY\"` |\n| `'Year'` | The year when each transaction was generated |\n| `'Month'` | The month when each transaction was generated |\n| `'Week'` | The week when each transaction was generated (`1`-`52`) |\n| `'Day'` | The day of the month when each transaction was generated (`1`-`31`) |\n| `'DayOfWeek'` | The day of the weeke when each transaction was generated <br>(`0` = Monday, `6` = Sunday) |","metadata":{},"id":"6918e18a-c248-4929-b552-7aee2057c0eb","cell_type":"markdown"},{"source":"from pyspark.sql import SparkSession\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.regression import RandomForestRegressor\nfrom pyspark.sql.functions import col, dayofmonth, month, year,  to_date, to_timestamp, weekofyear, dayofweek\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.evaluation import RegressionEvaluator","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1747207865413,"lastExecutedByKernel":"0f8e84e6-abb2-4989-a5ff-31195a5ee0b1","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from pyspark.sql import SparkSession\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.regression import RandomForestRegressor\nfrom pyspark.sql.functions import col, dayofmonth, month, year,  to_date, to_timestamp, weekofyear, dayofweek\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.evaluation import RegressionEvaluator"},"cell_type":"code","id":"2e6e130d-c501-4c09-9d2d-24d7cc0103d3","outputs":[],"execution_count":15},{"source":"Analyze the `Online Retail.csv` dataset and build a forecasting model to predict `'Quantity'` of products sold.\n\n- Split the data into two sets based on the splitting date, `\"2011-09-25\"`. All data up to and including this date should be in the training set, while data after this date should be in the test set. Return a pandas DataFrame, `pd_daily_train_data`, containing, at least, the columns `\"Country\"`, `\"StockCode\"`, `\"InvoiceDate\"`, `\"Quantity\"`.","metadata":{},"cell_type":"markdown","id":"5e35f4bd-4b5c-4949-befd-c471ce700a42"},{"source":"my_spark = SparkSession.builder.appName(\"SalesForecast\").getOrCreate()\n\n# Importing sales data\nsales_data = my_spark.read.csv(\"Online Retail.csv\", header=True, inferSchema=True, sep=\",\")\n\n# Convert InvoiceDate to datetime \nsales_data = sales_data.withColumn(\"InvoiceDate\", to_date(to_timestamp(col(\"InvoiceDate\"), \"d/M/yyyy H:mm\")))\n\n# Aggregate data into daily intervals\ndaily_sales_data = sales_data.groupBy(\"Country\", \"StockCode\", \"InvoiceDate\", \"Year\", \"Month\", \"Day\", \"Week\", \"DayOfWeek\").agg({\"Quantity\": \"sum\",                                                                                                           \"UnitPrice\": \"avg\"})\n\ndaily_sales_data = daily_sales_data.withColumnRenamed(\"sum(Quantity)\", \"Quantity\")","metadata":{"executionCancelledAt":null,"executionTime":696,"lastExecutedAt":1747207866110,"lastExecutedByKernel":"0f8e84e6-abb2-4989-a5ff-31195a5ee0b1","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"my_spark = SparkSession.builder.appName(\"SalesForecast\").getOrCreate()\n\n# Importing sales data\nsales_data = my_spark.read.csv(\"Online Retail.csv\", header=True, inferSchema=True, sep=\",\")\n\n# Convert InvoiceDate to datetime \nsales_data = sales_data.withColumn(\"InvoiceDate\", to_date(to_timestamp(col(\"InvoiceDate\"), \"d/M/yyyy H:mm\")))\n\n# Aggregate data into daily intervals\ndaily_sales_data = sales_data.groupBy(\"Country\", \"StockCode\", \"InvoiceDate\", \"Year\", \"Month\", \"Day\", \"Week\", \"DayOfWeek\").agg({\"Quantity\": \"sum\",                                                                                                           \"UnitPrice\": \"avg\"})\n\ndaily_sales_data = daily_sales_data.withColumnRenamed(\"sum(Quantity)\", \"Quantity\")"},"cell_type":"code","id":"b0b74bd1-a1fa-4464-977d-5bdd89b1eefe","outputs":[],"execution_count":16},{"source":"split_date_train_test = \"2011-09-25\"\n\n# Creating the train and test datasets\ntrain_data = daily_sales_data.filter(col(\"InvoiceDate\") <= split_date_train_test)\ntest_data = daily_sales_data.filter(col(\"InvoiceDate\") > split_date_train_test)\n\npd_daily_train_data = train_data.toPandas()\nprint(pd_daily_train_data)","metadata":{"executionCancelledAt":null,"executionTime":3296,"lastExecutedAt":1747207869408,"lastExecutedByKernel":"0f8e84e6-abb2-4989-a5ff-31195a5ee0b1","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"split_date_train_test = \"2011-09-25\"\n\n# Creating the train and test datasets\ntrain_data = daily_sales_data.filter(col(\"InvoiceDate\") <= split_date_train_test)\ntest_data = daily_sales_data.filter(col(\"InvoiceDate\") > split_date_train_test)\n\npd_daily_train_data = train_data.toPandas()\nprint(pd_daily_train_data)","outputsMetadata":{"0":{"height":38,"type":"stream"},"1":{"height":311,"type":"stream"}}},"cell_type":"code","id":"c5bd9027-4ea8-4410-bbbf-1ee9df178cb1","outputs":[{"output_type":"stream","name":"stderr","text":"                                                                                \r"},{"output_type":"stream","name":"stdout","text":"               Country StockCode  ... avg(UnitPrice)  Quantity\n0       United Kingdom     22912  ...           4.95         3\n1               France     22659  ...           1.95        24\n2       United Kingdom     21544  ...           0.85        12\n3       United Kingdom     21098  ...           1.25        16\n4               Norway     85150  ...           2.55        12\n...                ...       ...  ...            ...       ...\n175447  United Kingdom     23240  ...           4.15         6\n175448  United Kingdom     21908  ...           2.10         3\n175449  United Kingdom     23580  ...           1.95         9\n175450  United Kingdom    90200D  ...           4.25        12\n175451  United Kingdom     21213  ...           0.55        48\n\n[175452 rows x 10 columns]\n"}],"execution_count":17},{"source":"- Using your test set, calculate the Mean Absolute Error (MAE) for your forecast model for the `'Quantity'` sold? Return a double (float) named mae.","metadata":{},"cell_type":"markdown","id":"10c144fa-72af-476a-939f-269fdf460b4f"},{"source":"country_indexer = StringIndexer(inputCol=\"Country\", outputCol=\"CountryIndex\").setHandleInvalid(\"keep\")\nstock_code_indexer = StringIndexer(inputCol=\"StockCode\", outputCol=\"StockCodeIndex\").setHandleInvalid(\"keep\")\n\n\nfeature_cols = [\"CountryIndex\", \"StockCodeIndex\", \"Month\", \"Year\", \"DayOfWeek\", \"Day\", \"Week\"]\n\nassembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n\nrf = RandomForestRegressor(\n    featuresCol=\"features\",\n    labelCol=\"Quantity\",\n    maxBins=4000\n)\n\npipeline = Pipeline(stages=[country_indexer, stock_code_indexer, assembler, rf])\n\n# Training the model\nmodel = pipeline.fit(train_data)\n\n# Getting test predictions\ntest_predictions = model.transform(test_data)\ntest_predictions = test_predictions.withColumn(\"prediction\", col(\"prediction\").cast(\"double\"))\n\nmae_evaluator = RegressionEvaluator(\n    labelCol=\"Quantity\", predictionCol=\"prediction\", metricName=\"mae\")\n\nmae = mae_evaluator.evaluate(test_predictions)\nprint(mae)","metadata":{"executionCancelledAt":null,"executionTime":11458,"lastExecutedAt":1747207880866,"lastExecutedByKernel":"0f8e84e6-abb2-4989-a5ff-31195a5ee0b1","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"country_indexer = StringIndexer(inputCol=\"Country\", outputCol=\"CountryIndex\").setHandleInvalid(\"keep\")\nstock_code_indexer = StringIndexer(inputCol=\"StockCode\", outputCol=\"StockCodeIndex\").setHandleInvalid(\"keep\")\n\n\nfeature_cols = [\"CountryIndex\", \"StockCodeIndex\", \"Month\", \"Year\", \"DayOfWeek\", \"Day\", \"Week\"]\n\nassembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n\nrf = RandomForestRegressor(\n    featuresCol=\"features\",\n    labelCol=\"Quantity\",\n    maxBins=4000\n)\n\npipeline = Pipeline(stages=[country_indexer, stock_code_indexer, assembler, rf])\n\n# Training the model\nmodel = pipeline.fit(train_data)\n\n# Getting test predictions\ntest_predictions = model.transform(test_data)\ntest_predictions = test_predictions.withColumn(\"prediction\", col(\"prediction\").cast(\"double\"))\n\nmae_evaluator = RegressionEvaluator(\n    labelCol=\"Quantity\", predictionCol=\"prediction\", metricName=\"mae\")\n\nmae = mae_evaluator.evaluate(test_predictions)\nprint(mae)","outputsMetadata":{"0":{"height":38,"type":"stream"},"1":{"height":59,"type":"stream"},"2":{"height":38,"type":"stream"},"3":{"height":38,"type":"stream"},"4":{"height":38,"type":"stream"},"5":{"height":38,"type":"stream"},"6":{"height":38,"type":"stream"}}},"cell_type":"code","id":"e2e4900b-dddd-46f8-8b5e-5c7596adc086","outputs":[{"output_type":"stream","name":"stderr","text":"                                                                                \r"},{"output_type":"stream","name":"stdout","text":"25/05/14 07:31:14 WARN DAGScheduler: Broadcasting large task binary with size 1089.4 KiB\n25/05/14 07:31:15 WARN DAGScheduler: Broadcasting large task binary with size 1627.2 KiB\n"},{"output_type":"stream","name":"stderr","text":"                                                                                \r"},{"output_type":"stream","name":"stdout","text":"25/05/14 07:31:16 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n"},{"output_type":"stream","name":"stderr","text":"                                                                                \r"},{"output_type":"stream","name":"stdout","text":"9.472060129192593\n"},{"output_type":"stream","name":"stderr","text":"                                                                                \r"}],"execution_count":18},{"source":"- How many units are expected to be sold during the week `39` of 2011? Store as an integer variable called `quantity_sold_w39`.","metadata":{},"cell_type":"markdown","id":"115b6379-cda6-4fb4-b0e8-046a3476f274"},{"source":"weekly_test_predictions = test_predictions.groupBy(\"Year\", \"Week\").agg({\"prediction\": \"sum\"})\n\npromotion_week = weekly_test_predictions.filter((col('Week')==39) & (col('Year')==2011))\n\nquantity_sold_w39 = int(promotion_week.select(\"sum(prediction)\").collect()[0][0])\n\nmy_spark.stop()","metadata":{"executionCancelledAt":null,"executionTime":1114,"lastExecutedAt":1747207881980,"lastExecutedByKernel":"0f8e84e6-abb2-4989-a5ff-31195a5ee0b1","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"weekly_test_predictions = test_predictions.groupBy(\"Year\", \"Week\").agg({\"prediction\": \"sum\"})\n\npromotion_week = weekly_test_predictions.filter((col('Week')==39) & (col('Year')==2011))\n\nquantity_sold_w39 = int(promotion_week.select(\"sum(prediction)\").collect()[0][0])\n\nmy_spark.stop()"},"cell_type":"code","id":"d898a67a-a5a4-491e-a65b-54af00db0b40","outputs":[],"execution_count":19}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}