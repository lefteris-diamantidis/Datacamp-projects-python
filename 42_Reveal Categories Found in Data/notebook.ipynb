{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c79a760b-d438-41bb-b1a1-2578773c0fe0",
   "metadata": {},
   "source": [
    "![wordcloud](wordcloud.png)\n",
    "\n",
    "As a Data Scientist working for a mobile app company, you usually find yourself applying product analytics to better understand user behavior, uncover patterns, and reveal insights to identify the great and not-so-great features. Recently, the number of negative reviews has increased on Google Play, and as a consequence, the app's rating has been decreasing. The team has requested you to analyze the situation and make sense of the negative reviews.\n",
    "\n",
    "It's up to you to apply K-means clustering from scikit-learn and NLP techniques through NLTK to sort text data from negative reviews in the Google Play Store into categories!\n",
    "\n",
    "## The Data\n",
    "\n",
    "A dataset has been shared with a sample of reviews and their respective scores (from 1 to 5) in the Google Play Store. A summary and preview are provided below.\n",
    "\n",
    "# reviews.csv\n",
    "\n",
    "| Column     | Description              |\n",
    "|------------|--------------------------|\n",
    "| `'content'` | Content (text) of each review. |\n",
    "| `'score'` | Score assigned to the review by the user as an integer (from 1 to 5). |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3004deff-c318-41c2-a7e4-46ed10241f12",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 13,
    "lastExecutedAt": 1747205007293,
    "lastExecutedByKernel": "eb96d060-f110-4dc9-b29f-3fd84a3f3f64",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a350606-4857-413f-b0af-cf594f52f974",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 101,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/repl/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/repl/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary files from NLTK:\n",
    "# punkt -> Tokenization\n",
    "# stopwords -> Stop words removal\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef60922a-61c4-489f-9f2e-c8b540eec935",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 143,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  score\n",
      "0                      I cannot open the app anymore      1\n",
      "1  I have been begging for a refund from this app...      1\n",
      "2  Very costly for the premium version (approx In...      1\n",
      "3  Used to keep me organized, but all the 2020 UP...      1\n",
      "4                                Dan Birthday Oct 28      1\n"
     ]
    }
   ],
   "source": [
    "reviews = pd.read_csv(\"reviews.csv\")\n",
    "\n",
    "print(reviews.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef9bbf-6f41-44b1-9dbe-5442b289be56",
   "metadata": {},
   "source": [
    "To reveal the main topics from app reviews, you'll perform these tasks:\n",
    "\n",
    "Preprocess the negative reviews (reviews with a score of 1 or 2) by tokenizing the text, removing stop words and non-alpha characters. Save the results in a pandas DataFrame called `preprocessed_reviews`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65876f15-d09a-4b69-a628-b50c9a16d768",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 143,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review\n",
      "0                                   open app anymore\n",
      "1           begging refund app month nobody replying\n",
      "2  costly premium version approx Indian Rupees pe...\n",
      "3  Used keep organized UPDATES made mess things c...\n",
      "4                                   Dan Birthday Oct\n"
     ]
    }
   ],
   "source": [
    "negative_reviews_tmp = reviews[(reviews[\"score\"] == 1) | (reviews[\"score\"] == 2)][\"content\"]\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    filtered_tokens = [\n",
    "        token\n",
    "        for token in tokens\n",
    "        if token.isalpha() and token.lower() not in stopwords.words(\"english\")\n",
    "    ]\n",
    "\n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "\n",
    "negative_reviews_cleaned = negative_reviews_tmp.apply(preprocess_text)\n",
    "\n",
    "preprocessed_reviews = pd.DataFrame({\"review\": negative_reviews_cleaned})\n",
    "print(preprocessed_reviews.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdc3993-1d03-4931-b53f-22b125613477",
   "metadata": {},
   "source": [
    "Vectorize the cleaned negative reviews using TF-IDF and store the matrix in a variable called `tfidf_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17eb6110-1655-4a1d-b558-b83ec06baddb",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 292)\t0.7274120131461655\n",
      "  (0, 316)\t0.26084007427013295\n",
      "  (0, 4041)\t0.6346922236686016\n",
      "  (1, 4954)\t0.515334875276096\n",
      "  (1, 3882)\t0.47123926546563444\n",
      "  (1, 3738)\t0.32475682037507164\n",
      "  (1, 4826)\t0.3572537676591596\n",
      "  (1, 585)\t0.515334875276096\n",
      "  (1, 316)\t0.11703093798205348\n",
      "  (2, 2135)\t0.19146110029239458\n",
      "  (2, 3357)\t0.1435439718198807\n",
      "  (2, 3632)\t0.18717758003062893\n",
      "  (2, 6431)\t0.1140959667437744\n",
      "  (2, 6607)\t0.22676740734635442\n",
      "  (2, 309)\t0.3240018335942553\n",
      "  (2, 1736)\t0.20540435544097566\n",
      "  (2, 625)\t0.32463845282391557\n",
      "  (2, 6766)\t0.18457571967920094\n",
      "  (2, 4240)\t0.22676740734635442\n",
      "  (2, 5140)\t0.2902416713612349\n",
      "  (2, 2942)\t0.3090627238189522\n",
      "  (2, 347)\t0.3090627238189522\n",
      "  (2, 6489)\t0.2507216262520351\n",
      "  (2, 4463)\t0.26135698889158343\n",
      "  (2, 1265)\t0.2835241469753328\n",
      "  :\t:\n",
      "  (4847, 5447)\t0.15485015875850797\n",
      "  (4847, 4437)\t0.24552433334322854\n",
      "  (4847, 1203)\t0.2115800923452725\n",
      "  (4847, 3847)\t0.16388869773897538\n",
      "  (4847, 5353)\t0.20271133338548133\n",
      "  (4847, 2996)\t0.22543680593982587\n",
      "  (4847, 3412)\t0.17853836710942017\n",
      "  (4847, 2558)\t0.1297476164095533\n",
      "  (4847, 316)\t0.06286914398820408\n",
      "  (4848, 4609)\t0.22555091939150307\n",
      "  (4848, 5705)\t0.2688869992672439\n",
      "  (4848, 6507)\t0.4447111363090382\n",
      "  (4848, 2005)\t0.25729493195625064\n",
      "  (4848, 970)\t0.26335690323483213\n",
      "  (4848, 6711)\t0.18270075442237318\n",
      "  (4848, 3416)\t0.2674382431492904\n",
      "  (4848, 2238)\t0.1889911903019163\n",
      "  (4848, 6613)\t0.43227159982382357\n",
      "  (4848, 6572)\t0.1757405812366013\n",
      "  (4848, 2523)\t0.15334996214803054\n",
      "  (4848, 1297)\t0.26335690323483213\n",
      "  (4848, 2474)\t0.15522100821402848\n",
      "  (4848, 4826)\t0.24812078052291192\n",
      "  (4848, 316)\t0.08128061984538489\n",
      "  (4849, 4010)\t1.0\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(preprocessed_reviews[\"review\"])\n",
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17e463a-6d14-494e-8bb0-81c8e7bd5ca0",
   "metadata": {},
   "source": [
    "Apply K-means clustering to `tfidf_matrix` to group the reviews into five categories. Store the predicted labels in a list called `categories`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e6cc8f3-7ff9-4f72-b0b8-6c661bc0e380",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 3, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "clust_kmeans = KMeans(n_clusters=5, random_state=500)\n",
    "pred_labels = clust_kmeans.fit_predict(tfidf_matrix)\n",
    "\n",
    "# Store the predicted labels in a list variable called categories\n",
    "categories = pred_labels.tolist()\n",
    "preprocessed_reviews[\"category\"] = categories\n",
    "\n",
    "print(categories[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86607043-9a97-40e2-b080-54a9a9fb5cd3",
   "metadata": {},
   "source": [
    "For each unique cluster label, find the most frequent term. Store the results in a pandas DataFrame called `topic_terms` with at least three columns to store the label assigned from K-means, the identified term, and its frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee15d16d-6ccd-4180-95da-f9ebfdb48c0f",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 143,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   category      term   frequency\n",
      "0         0       app  186.525216\n",
      "1         1   version   63.738669\n",
      "2         2      good   52.935519\n",
      "3         3   premium   55.750426\n",
      "4         4  calendar   70.971649\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "topic_terms_list = []\n",
    "\n",
    "for cluster in range(clust_kmeans.n_clusters):\n",
    "\n",
    "    cluster_indices = [i for i, label in enumerate(categories) if label == cluster]\n",
    "\n",
    "    cluster_tfidf_sum = tfidf_matrix[cluster_indices].sum(axis=0)\n",
    "    cluster_term_freq = np.asarray(cluster_tfidf_sum).ravel()\n",
    "\n",
    "    top_term_index = cluster_term_freq.argsort()[::-1][0]\n",
    "\n",
    "    topic_terms_list.append(\n",
    "        {\n",
    "            \"category\": cluster,\n",
    "            \"term\": terms[top_term_index],\n",
    "            \"frequency\": cluster_term_freq[top_term_index],\n",
    "        }\n",
    "    )\n",
    "\n",
    "topic_terms = pd.DataFrame(topic_terms_list)\n",
    "\n",
    "print(topic_terms)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
