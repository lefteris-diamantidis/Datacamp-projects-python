{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35d4e17b-eeb6-40dd-a140-7b949390e115",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analyzing River Thames Water Levels\n",
    "Time series data is everywhere, from watching your stock portfolio to monitoring climate change, and even live-tracking as local cases of a virus become a global pandemic. In this project, you’ll work with a time series that tracks the tide levels of the Thames River. You’ll first load the data and inspect it data visually, and then perform calculations on the dataset to generate some summary statistics. You’ll end by reducing the time series to its component attributes and analyzing them. \n",
    "\n",
    "The original dataset is available from the British Oceanographic Data Center.\n",
    "\n",
    "Here's a map of the locations of the tidal meters along the River Thames in London.\n",
    "\n",
    "![](locations.png)\n",
    "\n",
    "The provided datasets are in the `data` folder in this workspace. For this project, you will work with one of these files, `10-11_London_Bridge.txt`, which contains comma separated values for water levels in the Thames River at the London Bridge. After you've finished the project, you can use your same code to analyze data from the other files (at other spots in the UK where tidal data is collected) if you'd like. \n",
    "\n",
    "The TXT file contains data for three variables, described in the table below. \n",
    "\n",
    "| Variable Name | Description | Format |\n",
    "| ------------- | ----------- | ------ |\n",
    "| Date and time | Date and time of measurement to GMT. Note the tide gauge is accurate to one minute. | dd/mm/yyyy hh:mm:ss |\n",
    "| Water level | High or low water level measured by tide meter. Tide gauges are accurate to 1 centimetre. | metres (Admiralty Chart Datum (CD), Ordnance Datum Newlyn (ODN or Trinity High Water (THW)) | \n",
    "| Flag | High water flag = 1, low water flag = 0 | Categorical (0 or 1) |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f94cd",
   "metadata": {},
   "source": [
    "Analyze Thames River tidal data to track changes in high-tide and low-tide frequency over time.\n",
    "\n",
    "The data is in the `data/10-11_London_Bridge.txt` file.\n",
    "\n",
    "- Find the mean, median, and interquartile range for high- and low-tide data and save them as two separate `pandas` Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8030819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date and time  water level (m ODN)   flag   HW=1 or LW=0\n",
      "0  01/05/1911 15:40:00               3.7130      1            NaN\n",
      "1  02/05/1911 11:25:00              -2.9415      0            NaN\n",
      "2  02/05/1911 16:05:00               3.3828      1            NaN\n",
      "3  03/05/1911 11:50:00              -2.6367      0            NaN\n",
      "4  03/05/1911 16:55:00               2.9256      1            NaN\n"
     ]
    }
   ],
   "source": [
    "# Package imports\n",
    "import pandas as pd                \n",
    "\n",
    "def IQR(column): \n",
    "    q25, q75 = column.quantile([0.25, 0.75])\n",
    "    return q75-q25\n",
    "\n",
    "# Load the data from London Bridge\n",
    "df = pd.read_csv('data/10-11_London_Bridge.txt') \n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69d24227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', 'water_level', 'is_high_tide'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=[' HW=1 or LW=0'], axis=1)\n",
    "df.columns = ['datetime', 'water_level', 'is_high_tide']\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80af150d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 115503 entries, 0 to 115502\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   datetime      115503 non-null  object\n",
      " 1   water_level   115503 non-null  object\n",
      " 2   is_high_tide  115503 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74ecd66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean      3.318373\n",
      "median    3.352600\n",
      "IQR       0.743600\n",
      "Name: water_level, dtype: float64\n",
      "mean     -2.383737\n",
      "median   -2.412900\n",
      "IQR       0.538200\n",
      "Name: water_level, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df['datetime'] = pd.to_datetime(df['datetime'], format=\"%d/%m/%Y %H:%M:%S\")\n",
    "df['water_level'] = df.water_level.astype(float)\n",
    "\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['year'] = df['datetime'].dt.year\n",
    "\n",
    "tide_high = df[df['is_high_tide'] == 1]\n",
    "tide_low = df[df['is_high_tide'] == 0]\n",
    "\n",
    "high_statistics = tide_high['water_level'].agg(['mean', 'median', IQR])\n",
    "low_statistics = tide_low['water_level'].agg(['mean', 'median', IQR])\n",
    "\n",
    "print(high_statistics)\n",
    "print(low_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5078f3d",
   "metadata": {},
   "source": [
    "- Calculate the annual percentage of days with very high tide levels (90th percentile of high tide days) and low-tide days (below the 10th percentile), and store the results for each year as floats in two two-column DataFrames with the index reset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75a7d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ratio of high tide days\n",
    "all_high_days = tide_high.groupby('year')['water_level'].count()\n",
    "very_high_days = tide_high[tide_high['water_level'] > tide_high['water_level'].quantile(0.90)].groupby('year')['water_level'].count()\n",
    "very_high_ratio = (very_high_days/all_high_days).reset_index()\n",
    "\n",
    "# Calculate ratio of low tide days\n",
    "all_low_days = tide_low.groupby('year')['water_level'].count()\n",
    "very_low_days = tide_low[tide_low['water_level'] < tide_low['water_level'].quantile(0.10)].groupby('year')['water_level'].count()\n",
    "very_low_ratio = (very_low_days/all_low_days).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24115f4b",
   "metadata": {},
   "source": [
    "- Create a dictionary named `solution` with a summary of your data analysis, with these key-value pairs:\n",
    "\n",
    "`{high_statistics: high-tide stats, low_statistics: low-tide stats, very_high_ratio: high-tide ratio data, very_low_ratio: low-tide ratio data}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ca4359b-3fb7-4cfc-8017-36f70e928fba",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 543,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'high_statistics': mean      3.318373\n",
      "median    3.352600\n",
      "IQR       0.743600\n",
      "Name: water_level, dtype: float64, 'low_statistics': mean     -2.383737\n",
      "median   -2.412900\n",
      "IQR       0.538200\n",
      "Name: water_level, dtype: float64, 'very_high_ratio':     year  water_level\n",
      "0   1911     0.004098\n",
      "1   1912     0.032316\n",
      "2   1913     0.082212\n",
      "3   1914     0.055313\n",
      "4   1915     0.045045\n",
      "..   ...          ...\n",
      "80  1991     0.096317\n",
      "81  1992     0.103253\n",
      "82  1993     0.145923\n",
      "83  1994     0.150355\n",
      "84  1995     0.170213\n",
      "\n",
      "[85 rows x 2 columns], 'very_low_ratio':     year  water_level\n",
      "0   1911     0.060606\n",
      "1   1912     0.066667\n",
      "2   1913     0.022388\n",
      "3   1914     0.039017\n",
      "4   1915     0.033435\n",
      "..   ...          ...\n",
      "80  1991     0.150355\n",
      "81  1992     0.107496\n",
      "82  1993     0.112696\n",
      "83  1994     0.106383\n",
      "84  1995     0.107801\n",
      "\n",
      "[85 rows x 2 columns]}\n"
     ]
    }
   ],
   "source": [
    "solution = {'high_statistics': high_statistics, 'low_statistics': low_statistics, 'very_high_ratio': very_high_ratio, 'very_low_ratio':very_low_ratio}\n",
    "\n",
    "print(solution)"
   ]
  }
 ],
 "metadata": {
  "editor": "DataCamp Workspace",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
