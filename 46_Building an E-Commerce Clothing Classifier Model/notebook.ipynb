{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaa02648-9eae-45ba-893f-88440e8e4235",
   "metadata": {},
   "source": [
    "![clothing_classification](clothing_classification.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5a988c-1095-485a-a88c-002400a872be",
   "metadata": {},
   "source": [
    "Fashion Forward is a new AI-based e-commerce clothing retailer.\n",
    "They want to use image classification to automatically categorize new product listings, making it easier for customers to find what they're looking for. It will also assist in inventory management by quickly sorting items.\n",
    "\n",
    "As a data scientist tasked with implementing a garment classifier, your primary objective is to develop a machine learning model capable of accurately categorizing images of clothing items into distinct garment types such as shirts, trousers, shoes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e7dae3-c192-4267-a0ed-18d1ac56c861",
   "metadata": {
    "collapsed": true,
    "executionCancelledAt": null,
    "executionTime": 6530,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "lastExecutedAt": 1732035879941,
    "lastExecutedByKernel": "7c3d6045-0e62-4f57-8299-e594a5d95b2a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "!pip install torchmetrics\n!pip install torchvision",
    "outputsMetadata": {
     "0": {
      "height": 544,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "# !pip install torchmetrics\n",
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f71a8372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import Accuracy, Precision, Recall\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ddeb3d",
   "metadata": {},
   "source": [
    "Automate product tagging for the e-commerce store using CNNs.\n",
    "\n",
    "- Once trained (keeping the epochs to 1 or 2 to keep the run time down), store your predictions on the test set in a list named `predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc798af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train_data.classes\n",
    "num_classes = len(train_data.classes)\n",
    "\n",
    "# Define some relevant variables\n",
    "num_input_channels = 1\n",
    "num_output_channels = 16\n",
    "image_size = train_data[0][0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d615c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassImageClassifier(nn.Module):\n",
    "\n",
    "    # Define the init method\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultiClassImageClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_input_channels, num_output_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Create a fully connected layer\n",
    "        self.fc = nn.Linear(num_output_channels * (image_size//2)**2, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass inputs through each layer\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74141213",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=10,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "785a8fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function\n",
    "def train_model(optimizer, net, num_epochs):\n",
    "    num_processed = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0\n",
    "        num_processed = 0\n",
    "        for features, labels in dataloader_train:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            num_processed += len(labels)\n",
    "        print(f'epoch {epoch}, loss: {running_loss / num_processed}')\n",
    "        \n",
    "    train_loss = running_loss / len(dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8718714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 0.0400162578270693\n"
     ]
    }
   ],
   "source": [
    "net = MultiClassImageClassifier(num_classes)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "train_model(\n",
    "    optimizer=optimizer,\n",
    "    net=net,\n",
    "    num_epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ecc0af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_test = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "accuracy_metric = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "precision_metric = Precision(task='multiclass', num_classes=num_classes, average=None)\n",
    "recall_metric = Recall(task='multiclass', num_classes=num_classes, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5305965",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "predictions = []\n",
    "for i, (features, labels) in enumerate(dataloader_test):\n",
    "    output = net.forward(features.reshape(-1, 1, image_size, image_size))\n",
    "    cat = torch.argmax(output, dim=-1)\n",
    "    predictions.extend(cat.tolist())\n",
    "    accuracy_metric(cat, labels)\n",
    "    precision_metric(cat, labels)\n",
    "    recall_metric(cat, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9e43d5",
   "metadata": {},
   "source": [
    "- Calculate the accuracy, and per-class precision and recall for your classifier based on the predictions obtained. Store your metrics in variables named `accuracy`, `precision`, and `recall`. Use lists of the appropriate length for the precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16351422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8783000111579895\n",
      "Precision (per class): [0.8509968519210815, 0.9827761054039001, 0.7819687128067017, 0.842056930065155, 0.8567901253700256, 0.9759036302566528, 0.654285728931427, 0.9515640735626221, 0.954901933670044, 0.9488692283630371]\n",
      "Recall (per class): [0.8109999895095825, 0.9700000286102295, 0.8500000238418579, 0.9169999957084656, 0.6940000057220459, 0.972000002861023, 0.6869999766349792, 0.9430000185966492, 0.9739999771118164, 0.9649999737739563]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_metric.compute().item()\n",
    "precision = precision_metric.compute().tolist()\n",
    "recall = recall_metric.compute().tolist()\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision (per class):', precision)\n",
    "print('Recall (per class):', recall)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
