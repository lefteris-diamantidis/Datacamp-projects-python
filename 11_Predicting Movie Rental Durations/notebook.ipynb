{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4ae5707-109f-4cd6-8168-88cac0179d6b",
   "metadata": {},
   "source": [
    "![dvd_image](dvd_image.jpg)\n",
    "\n",
    "A DVD rental company needs your help! They want to figure out how many days a customer will rent a DVD for based on some features and has approached you for help. They want you to try out some regression models which will help predict the number of days a customer will rent a DVD for. The company wants a model which yeilds a MSE of 3 or less on a test set. The model you make will help the company become more efficient inventory planning.\n",
    "\n",
    "The data they provided is in the csv file `rental_info.csv`. It has the following features:\n",
    "- `\"rental_date\"`: The date (and time) the customer rents the DVD.\n",
    "- `\"return_date\"`: The date (and time) the customer returns the DVD.\n",
    "- `\"amount\"`: The amount paid by the customer for renting the DVD.\n",
    "- `\"amount_2\"`: The square of `\"amount\"`.\n",
    "- `\"rental_rate\"`: The rate at which the DVD is rented for.\n",
    "- `\"rental_rate_2\"`: The square of `\"rental_rate\"`.\n",
    "- `\"release_year\"`: The year the movie being rented was released.\n",
    "- `\"length\"`: Lenght of the movie being rented, in minuites.\n",
    "- `\"length_2\"`: The square of `\"length\"`.\n",
    "- `\"replacement_cost\"`: The amount it will cost the company to replace the DVD.\n",
    "- `\"special_features\"`: Any special features, for example trailers/deleted scenes that the DVD also has.\n",
    "- `\"NC-17\"`, `\"PG\"`, `\"PG-13\"`, `\"R\"`: These columns are dummy variables of the rating of the movie. It takes the value 1 if the move is rated as the column name and 0 otherwise. For your convinience, the reference dummy has already been dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2dcdf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Import any additional modules and start coding below\n",
    "\n",
    "# For lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Run OLS\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03917c7a",
   "metadata": {},
   "source": [
    "As with most data science projects, you will need to pre-process the data provided, in this case, a csv file called `rental_info.csv`. Specifically, you need to:\n",
    "\n",
    "- Read in the csv file `rental_info.csv` using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d678abf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 rental_date                return_date  amount  release_year  rental_rate  length  replacement_cost                special_features  NC-17  PG  PG-13  R  amount_2  length_2  rental_rate_2\n",
      "0  2005-05-25 02:54:33+00:00  2005-05-28 23:40:33+00:00    2.99        2005.0         2.99   126.0             16.99  {Trailers,\"Behind the Scenes\"}      0   0      0  1    8.9401   15876.0         8.9401\n",
      "1  2005-06-15 23:19:16+00:00  2005-06-18 19:24:16+00:00    2.99        2005.0         2.99   126.0             16.99  {Trailers,\"Behind the Scenes\"}      0   0      0  1    8.9401   15876.0         8.9401\n",
      "2  2005-07-10 04:27:45+00:00  2005-07-17 10:11:45+00:00    2.99        2005.0         2.99   126.0             16.99  {Trailers,\"Behind the Scenes\"}      0   0      0  1    8.9401   15876.0         8.9401\n",
      "3  2005-07-31 12:06:41+00:00  2005-08-02 14:30:41+00:00    2.99        2005.0         2.99   126.0             16.99  {Trailers,\"Behind the Scenes\"}      0   0      0  1    8.9401   15876.0         8.9401\n",
      "4  2005-08-19 12:30:04+00:00  2005-08-23 13:35:04+00:00    2.99        2005.0         2.99   126.0             16.99  {Trailers,\"Behind the Scenes\"}      0   0      0  1    8.9401   15876.0         8.9401\n"
     ]
    }
   ],
   "source": [
    "df_rental = pd.read_csv(\"rental_info.csv\")\n",
    "\n",
    "print(df_rental.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08442417",
   "metadata": {},
   "source": [
    "- Create a column named `\"rental_length_days\"` using the columns `\"return_date\"` and `\"rental_date\"`, and add it to the `pandas` DataFrame.     \n",
    "    This column should contain information on how many days a DVD has been rented by a customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c16ff764",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rental[\"rental_length\"] = pd.to_datetime(df_rental[\"return_date\"]) - pd.to_datetime(df_rental[\"rental_date\"])\n",
    "df_rental[\"rental_length_days\"] = df_rental[\"rental_length\"].dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0690ee26",
   "metadata": {},
   "source": [
    "- Create two columns of dummy variables from `\"special_features\"`, which takes the value of 1 when:\n",
    "    - The value is `\"Deleted Scenes\"`, storing as a column called `\"deleted_scenes\"`.\n",
    "    - The value is `\"Behind the Scenes\"`, storing as a column called `\"behind_the_scenes\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7ede566-910a-445c-b11a-68d192ac8506",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 23441,
    "lastExecutedAt": 1724101529831,
    "lastExecutedByKernel": "615764af-bea0-4dfa-a3e5-40c37caebe36",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n# Import any additional modules and start coding below\n\n# For lasso\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Run OLS\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Random forest\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Read in data\ndf_rental = pd.read_csv(\"rental_info.csv\")\n\n# Add information on rental duration\ndf_rental[\"rental_length\"] = pd.to_datetime(df_rental[\"return_date\"]) - pd.to_datetime(df_rental[\"rental_date\"])\ndf_rental[\"rental_length_days\"] = df_rental[\"rental_length\"].dt.days\n\n### Add dummy variables\n# Add dummy for deleted scenes\ndf_rental[\"deleted_scenes\"] =  np.where(df_rental[\"special_features\"].str.contains(\"Deleted Scenes\"), 1, 0)\n# Add dummy for behind the scenes\ndf_rental[\"behind_the_scenes\"] =  np.where(df_rental[\"special_features\"].str.contains(\"Behind the Scenes\"), 1, 0)\n\n# Choose columns to drop\ncols_to_drop = [\"special_features\", \"rental_length\", \"rental_length_days\", \"rental_date\", \"return_date\"]\n\n# Split into feature and target sets\nX = df_rental.drop(cols_to_drop, axis=1)\ny = df_rental[\"rental_length_days\"]\n\n# Further split into training and test data\nX_train,X_test,y_train,y_test = train_test_split(X, \n                                                 y, \n                                                 test_size=0.2, \n                                                 random_state=9)\n\n# Create the Lasso model\nlasso = Lasso(alpha=0.3, random_state=9) \n\n# Train the model and access the coefficients\nlasso.fit(X_train, y_train)\nlasso_coef = lasso.coef_\n\n# Perform feature selectino by choosing columns with positive coefficients\nX_lasso_train, X_lasso_test = X_train.iloc[:, lasso_coef > 0], X_test.iloc[:, lasso_coef > 0]\n\n# Run OLS models on lasso chosen regression\nols = LinearRegression()\nols = ols.fit(X_lasso_train, y_train)\ny_test_pred = ols.predict(X_lasso_test)\nmse_lin_reg_lasso = mean_squared_error(y_test, y_test_pred)\n\n# Random forest hyperparameter space\nparam_dist = {'n_estimators': np.arange(1,101,1),\n          'max_depth':np.arange(1,11,1)}\n\n# Create a random forest regressor\nrf = RandomForestRegressor()\n\n# Use random search to find the best hyperparameters\nrand_search = RandomizedSearchCV(rf, \n                                 param_distributions=param_dist, \n                                 cv=5, \n                                 random_state=9)\n\n# Fit the random search object to the data\nrand_search.fit(X_train, y_train)\n\n# Create a variable for the best hyper param\nhyper_params = rand_search.best_params_\n\n# Run the random forest on the chosen hyper parameters\nrf = RandomForestRegressor(n_estimators=hyper_params[\"n_estimators\"], \n                           max_depth=hyper_params[\"max_depth\"], \n                           random_state=9)\nrf.fit(X_train,y_train)\nrf_pred = rf.predict(X_test)\nmse_random_forest= mean_squared_error(y_test, rf_pred)\n\n# Random forest gives lowest MSE so:\nbest_model = rf\nbest_mse = mse_random_forest",
    "outputsMetadata": {
     "0": {
      "height": 321,
      "type": "dataFrame"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Add dummy for deleted scenes\n",
    "df_rental[\"deleted_scenes\"] =  np.where(df_rental[\"special_features\"].str.contains(\"Deleted Scenes\"), 1, 0)\n",
    "# Add dummy for behind the scenes\n",
    "df_rental[\"behind_the_scenes\"] =  np.where(df_rental[\"special_features\"].str.contains(\"Behind the Scenes\"), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf62aee",
   "metadata": {},
   "source": [
    "- Make a `pandas` DataFrame called `X` containing all the appropriate features you can use to run the regression models, avoiding columns that leak data about the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae33b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose columns to drop\n",
    "cols_to_drop = [\"special_features\", \"rental_length\", \"rental_length_days\", \"rental_date\", \"return_date\"]\n",
    "\n",
    "# Split into feature and target sets\n",
    "X = df_rental.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b997e56",
   "metadata": {},
   "source": [
    "- Choose the `\"rental_length_days\"` as the target column and save it as a pandas Series called `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "173d1839",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_rental[\"rental_length_days\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a8e9ea",
   "metadata": {},
   "source": [
    "Following the preprocessing you will need to:\n",
    "\n",
    "- Split the data into `X_train`, `y_train`, `X_test`, and `y_test` train and test sets, avoiding any features that leak data about the target variable, and include 20% of the total data in the test set.\n",
    "- **Set `random_state` to `9`** whenever you use a function/method involving randomness, for example, when doing a test-train split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bc5fcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further split into training and test data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae56f1",
   "metadata": {},
   "source": [
    "**Recommend a model yielding a mean squared error (MSE) less than 3 on the test set**\n",
    "\n",
    "Save the model you would recommend as a variable named `best_model`, and save its MSE on the test set as `best_mse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eb49f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.941723864697602\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr = lr.fit(X_train, y_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "mse_lr = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(mse_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812692a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.225667528098759\n"
     ]
    }
   ],
   "source": [
    "param_dist = {'n_estimators': np.arange(1,101,1), 'max_depth':np.arange(1,11,1)}\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "rand_search = RandomizedSearchCV(rf, param_distributions=param_dist, cv=5, random_state=9)\n",
    "\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "hyper_params = rand_search.best_params_\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=hyper_params[\"n_estimators\"],  max_depth=hyper_params[\"max_depth\"], random_state=9)\n",
    "rf.fit(X_train,y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "mse_random_forest= mean_squared_error(y_test, rf_pred)\n",
    "\n",
    "print(mse_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "146d19ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest gives lowest MSE so:\n",
    "best_model = rf\n",
    "best_mse = mse_random_forest"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
