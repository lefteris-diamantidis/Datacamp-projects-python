{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83d925dc-90b3-40fa-b8d6-28728dddba3b",
   "metadata": {},
   "source": [
    "<img src=\"data/pexels-sammsara-luxury-modern-home-372468-1099816.jpg\" alt=\"E-commerce Home Decor Goods\" width=\"600\">\n",
    "\n",
    "E-commerce businesses rely on explainable artificial intelligence (AI) models to anticipate customer needs, improve inventory planning, personalize marketing campaigns, and most importantly, explain the results to stakeholders. Understanding what factors drive purchases in a specific product category, such as home decor, can help businesses tailor their strategies to maximize sales. If a company knows that customers who historically spend more on children's accessories would also spend more on home decor items moving forward, they could target these customers with promotional ads on home decor items and give bundling discounts to foster this pattern.\n",
    "\n",
    "A major online retailer has enlisted your help for this very task. You already have two forecast models (`model.pkl`, `knn_model.pkl`) and now you need to explain the results to stakeholders so they can make key business decisions about marketing and budgets.\n",
    "\n",
    "---\n",
    "## Data\n",
    "\n",
    "Each row in `X_train` represents a snapshot of a customer's features for a specific month, and `y_train` is the customer's sales for the next month for the `'home_decor'` product category. The data is a modified version of the original data that is publicly available on Kaggle.\n",
    "\n",
    "[//]: # (https://www.kaggle.com/datasets/gabrielramos87/an-online-shop-business/data)\n",
    "\n",
    "### X_train/X_test.csv\n",
    "\n",
    "| Column | Description |\n",
    "|--------|------------|\n",
    "| `logsales` | Logarithm of (customer sales+1) (+1 to handle 0 sales) |\n",
    "| `lag1` | The log of sales from 1 month ago |\n",
    "| `lag2`| The log of sales from 2 months ago|\n",
    "| `sma_2m` | Average log sales over the last 2 months (simple moving average)|\n",
    "| `sma_4m` | Average log sales over the last 4 months (simple moving average)|\n",
    "| `sma_6m` | Average log sales over the last 5 months (simple moving average)|\n",
    "| `months_since_first` | Months since first purchase |\n",
    "|<ul><li>`children_s_accessories`</li><li>`colourful_essentials`</li><li>`home_decor`</li><li>`home_storage`</li><li>`quirky_stationery`</li><li>`soft_furnishings`</li><li>`toys_games`</li>...</ul> | Category-specific logarithm of (customer sales+1) | \n",
    "| <ul><li>`sma_2m__birthday_gifts`</li><li>`sma_4m__birthday_gifts`</li><li>`sma_3m__birthday_gifts` | 2, 4, 6-month average log sales per category (simple moving average)|\n",
    "\n",
    "### y_train/y_test.csv\n",
    "\n",
    "- `'nextmonth__home_decor'`: Logarithm of (customer sales+1) for the `home_decor` product category in the next month for prediction\n",
    "\n",
    "---\n",
    "## Model\n",
    "\n",
    "This forecast model has been trained on the `X_train`, `y_train` provided.\n",
    "\n",
    "### model.pkl\n",
    "\n",
    "- Fitted `sklearn.ensemble.RandomForestRegressor` on `X_train`, `y_train`\n",
    "\n",
    "### knn_model.pkl\n",
    "\n",
    "- Fitted `sklearn.neighbors.KNeighborsRegressor` on `X_train`, `y_train`\n",
    "\n",
    "___\n",
    "### Update to Python 3.10\n",
    "\n",
    "Due to how frequently the libraries required for this project are updated, you'll need to update your environment to Python 3.10:\n",
    "\n",
    "1. In the workbook, click on \"Environment,\" in the top toolbar and select \"Session details\".\n",
    "\n",
    "2. In the workbook language dropdown, select \"Python 3.10\".\n",
    "\n",
    "3. Click \"Confirm\" and hit \"Done\" once the session is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47151c48-2744-42f5-8840-061304794c4e",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 196,
    "lastExecutedAt": 1747212513866,
    "lastExecutedByKernel": "2055ee5e-a115-4bd0-af0f-dceb66543133",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Re-run this cell\n# Import required libraries\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\nimport pandas as pd\nimport joblib\nimport sys\nassert (\n    sys.version_info.major == 3 and sys.version_info.minor == 10\n), \"Please ensure that you are on Python 3.10.\"\n\n# Load a sample of the data and the models\nX_train = pd.read_csv(\"data/X_train.csv\").sample(500, random_state=42)\nX_test = pd.read_csv(\"data/X_test.csv\").sample(500, random_state=42)\ny_train = pd.read_csv(\"data/y_train.csv\")[\"nextmonth__home_decor\"].sample(500, random_state=42)\ny_test = pd.read_csv(\"data/y_test.csv\")[\"nextmonth__home_decor\"].sample(500, random_state=42)\nmodel = joblib.load(\"data/model.pkl\")\nknn_model = joblib.load(\"data/knn_model.pkl\")"
   },
   "outputs": [],
   "source": [
    "# Re-run this cell\n",
    "# Import required libraries\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import sys\n",
    "assert (\n",
    "    sys.version_info.major == 3 and sys.version_info.minor == 10\n",
    "), \"Please ensure that you are on Python 3.10.\"\n",
    "\n",
    "# Load a sample of the data and the models\n",
    "X_train = pd.read_csv(\"data/X_train.csv\").sample(500, random_state=42)\n",
    "X_test = pd.read_csv(\"data/X_test.csv\").sample(500, random_state=42)\n",
    "y_train = pd.read_csv(\"data/y_train.csv\")[\"nextmonth__home_decor\"].sample(500, random_state=42)\n",
    "y_test = pd.read_csv(\"data/y_test.csv\")[\"nextmonth__home_decor\"].sample(500, random_state=42)\n",
    "model = joblib.load(\"data/model.pkl\")\n",
    "knn_model = joblib.load(\"data/knn_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc303b6-6a10-427c-a7df-147f5b4073d2",
   "metadata": {},
   "source": [
    "Explore `model`, `knn_model`, `X_test`, `y_test`, and use Explainable AI (XAI) to answer the following questions:\n",
    "\n",
    "- Identify an XAI method that assigns feature attributions using game theory principles and save the library name as a `str` variable, `xai`. Import this library to complete the remaining tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6400efdc-1c3c-4214-90ae-bde9db82b9b0",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 49,
    "lastExecutedAt": 1747212513918,
    "lastExecutedByKernel": "2055ee5e-a115-4bd0-af0f-dceb66543133",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Start coding here\n# Use as many cells as you need\n\n# Here is a view of how the RandomForestRegressor model was fitted:\n# from sklearn.ensemble import RandomForestRegressor\n# model = RandomForestRegressor(\n#     **{\n#         \"max_depth\": 16,\n#         \"min_samples_split\": 12,\n#         \"min_samples_leaf\": 7,\n#         \"max_features\": \"sqrt\",\n#         \"bootstrap\": False,\n#         \"random_state\": 42,\n#         \"n_jobs\": -1,\n#     }\n# )\n# model.fit(X_train, y_train)\n\n# Identify a game theory-based XAI method\n\nxai = \"shap\"\n\n# Import this library\nimport shap",
    "outputsMetadata": {
     "1": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Start coding here\n",
    "# Use as many cells as you need\n",
    "\n",
    "# Here is a view of how the RandomForestRegressor model was fitted:\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# model = RandomForestRegressor(\n",
    "#     **{\n",
    "#         \"max_depth\": 16,\n",
    "#         \"min_samples_split\": 12,\n",
    "#         \"min_samples_leaf\": 7,\n",
    "#         \"max_features\": \"sqrt\",\n",
    "#         \"bootstrap\": False,\n",
    "#         \"random_state\": 42,\n",
    "#         \"n_jobs\": -1,\n",
    "#     }\n",
    "# )\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# Identify a game theory-based XAI method\n",
    "\n",
    "xai = \"shap\"\n",
    "\n",
    "# Import this library\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7f29f9-0ecd-47ea-a708-4549817ae71b",
   "metadata": {},
   "source": [
    "- Compute feature importance based on the `model`'s predictions on `X_test`. Extract the top five features and store them as a DataFrame in `top_feats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f489b09e-0f62-4bfc-a692-6709f28cfa65",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 5758,
    "lastExecutedAt": 1747212519677,
    "lastExecutedByKernel": "2055ee5e-a115-4bd0-af0f-dceb66543133",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Compute feature importance based on the model's predictions on X_test. Extract the top five features and store them as a set in top_feats\n\n# Use Shap's TreeExplainer since RandomForestRegressor is a Tree-based model\nexplainer = shap.TreeExplainer(model)\n\n# Calculate SHAP values\nshap_values = explainer.shap_values(X_test)\n\n# Get feature importances\nfeature_importance = np.abs(shap_values).mean(axis=0)\n\n# Create a DataFrame of the feature importance\nfeature_importance_df = pd.DataFrame(\n    {\"Feature\": X_test.columns, \"Importance\": feature_importance}\n).sort_values(by=\"Importance\", ascending=False)\n\n# Top five most impactful features based on SHAP\ntop_feats = feature_importance_df.head(5)\nprint(top_feats)",
    "outputsMetadata": {
     "0": {
      "height": 143,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Feature  Importance\n",
      "2                           lag2    0.117177\n",
      "4                         sma_4m    0.098794\n",
      "1                           lag1    0.095220\n",
      "3                         sma_2m    0.059562\n",
      "44  sma_2m__colourful_essentials    0.058533\n"
     ]
    }
   ],
   "source": [
    "# Compute feature importance based on the model's predictions on X_test. Extract the top five features and store them as a set in top_feats\n",
    "\n",
    "# Use Shap's TreeExplainer since RandomForestRegressor is a Tree-based model\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importance = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "# Create a DataFrame of the feature importance\n",
    "feature_importance_df = pd.DataFrame(\n",
    "    {\"Feature\": X_test.columns, \"Importance\": feature_importance}\n",
    ").sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Top five most impactful features based on SHAP\n",
    "top_feats = feature_importance_df.head(5)\n",
    "print(top_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac073fc-8ccb-4372-8f16-bb8acd85dd5b",
   "metadata": {},
   "source": [
    "- Compute and extract the top five features for the `knn_model` (use `.sample(50, random_state=42)` for faster running) and evaluate the consistency across both models (`model`, `knn_model`). Save the consistency as a variable `consistency`, rounded to two decimal places and of type `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd3327f7-ddd0-45d4-bfb2-34e20cd7dbcc",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48597,
    "lastExecutedAt": 1747212568274,
    "lastExecutedByKernel": "2055ee5e-a115-4bd0-af0f-dceb66543133",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Evaluate the consistency of feature importance explanations across the two models provided\n\n# Here is a view of how the k-NN model was fitted:\n# knn_model = KNeighborsRegressor(\n#     n_neighbors=80,\n#     weights=\"uniform\",\n#     algorithm=\"auto\",\n#     leaf_size=30,\n#     p=2,\n#     metric=\"minkowski\",\n#     metric_params=None,\n#     n_jobs=-1,\n# )\n\n# Create a SHAP Kernel Explainer\nknn_explainer = shap.KernelExplainer(knn_model.predict, shap.kmeans(X_test, 5))\n\n# Calculate SHAP values\nknn_shap_values = knn_explainer.shap_values(X_test.sample(50, random_state=42))\n\n# Get feature importance\nknn_feature_importance = np.abs(knn_shap_values).mean(axis=0)\n\n# Create a DataFrame of the feature importance\nknn_feature_importance_df = pd.DataFrame(\n  {\"Feature\": X_test.columns, \"Importance\": knn_feature_importance}\n).sort_values(by=\"Importance\", ascending=False)\n\n# Top five most impactful features based on SHAP\nknn_top_feats = knn_feature_importance_df.head(5)\n\n# Calculate cosine similarty consistency across both models\nconsistency = round(cosine_similarity([feature_importance], [knn_feature_importance])[0][0], 2)\nprint(\"Consistency between SHAP values:\", consistency)"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8ad94bb780427586d6a98786b85889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency between SHAP values: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the consistency of feature importance explanations across the two models provided\n",
    "\n",
    "# Here is a view of how the k-NN model was fitted:\n",
    "# knn_model = KNeighborsRegressor(\n",
    "#     n_neighbors=80,\n",
    "#     weights=\"uniform\",\n",
    "#     algorithm=\"auto\",\n",
    "#     leaf_size=30,\n",
    "#     p=2,\n",
    "#     metric=\"minkowski\",\n",
    "#     metric_params=None,\n",
    "#     n_jobs=-1,\n",
    "# )\n",
    "\n",
    "# Create a SHAP Kernel Explainer\n",
    "knn_explainer = shap.KernelExplainer(knn_model.predict, shap.kmeans(X_test, 5))\n",
    "\n",
    "# Calculate SHAP values\n",
    "knn_shap_values = knn_explainer.shap_values(X_test.sample(50, random_state=42))\n",
    "\n",
    "# Get feature importance\n",
    "knn_feature_importance = np.abs(knn_shap_values).mean(axis=0)\n",
    "\n",
    "# Create a DataFrame of the feature importance\n",
    "knn_feature_importance_df = pd.DataFrame(\n",
    "  {\"Feature\": X_test.columns, \"Importance\": knn_feature_importance}\n",
    ").sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Top five most impactful features based on SHAP\n",
    "knn_top_feats = knn_feature_importance_df.head(5)\n",
    "\n",
    "# Calculate cosine similarty consistency across both models\n",
    "consistency = round(cosine_similarity([feature_importance], [knn_feature_importance])[0][0], 2)\n",
    "print(\"Consistency between SHAP values:\", consistency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f1bae2-e099-4380-b2a9-d4999769667b",
   "metadata": {},
   "source": [
    "- The marketing team wants to know if your model interpretations are stable and reliable. Save your response (\"yes\", \"no\") to `reliable`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8adf8d0b-c9d3-4bf2-9d52-bc568c40c068",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 112,
    "lastExecutedAt": 1747212568387,
    "lastExecutedByKernel": "2055ee5e-a115-4bd0-af0f-dceb66543133",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# The marketing team wants to know if your models are stable and reliable. What is your response?\nreliable = \"yes\"\nprint(reliable)"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "# The marketing team wants to know if your models are stable and reliable. What is your response?\n",
    "reliable = \"yes\"\n",
    "print(reliable)"
   ]
  }
 ],
 "metadata": {
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
